# robots.txt for eHack Global Technology

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow crawling of admin and private areas
Disallow: /api/
Disallow: /_next/
Disallow: /admin/
Disallow: /.git/

# Disallow crawling of specific file types
Disallow: /*.json$
Disallow: /*.env$

# Allow crawling of important static assets
Allow: /_next/static/
Allow: /_next/image/

# Sitemap location
Sitemap: https://ehackglobaltechnology.com/sitemap.xml

# Crawl-delay (optional - adjust if needed)
# Crawl-delay: 1

# Specific rules for major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block bad bots (optional - uncomment if needed)
# User-agent: AhrefsBot
# Disallow: /

# User-agent: SemrushBot
# Disallow: /
